dataset:
  name: "BDD100K"
  root_dir: "/mnt/team-share/Datasets/bdd-datasets/BDD/bdd_100k/"
  train_split: "images/100k/train/"
  val_split: "images/100k/val/"
  test_split: "images/100k/test/"
  train_ann_file: "labels/bdd100k_labels_images_train.json"
  val_ann_file: "labels/bdd100k_labels_images_val.json"
  test_ann_file: "labels/bdd100k_labels_images_test.json"
  convert_to_coco: true
  export_coco_path: "/mnt/team-share/Datasets/bdd-datasets/BDD/bdd_100k/coco_format/"

model:
  name: "gai-yolov12"
  variant: "n"  # Model variant: n (nano), s (small), m (medium), l (large), x (xlarge)
  pretrained: true
  num_classes: 10
  input_size: [640, 640]

dataloader:
  batch_size: 64
  num_workers: 16
  pin_memory: true
  shuffle: true

training:
  num_epochs: 50
  learning_rate: 0.001
  weight_decay: 0.0001
  warmup_epochs: 3
  checkpoint_interval: 5  # Save checkpoint every N epochs
  gradient_clip_norm: 10.0  # Gradient clipping

augmentation:
  mixup_prob: 0.15
  cutmix_prob: 0.15
  mosaic_prob: 0.5
  augmentation_strategies:
    - "RandomHorizontalFlip"
    - "RandomCrop"
    - "ColorJitter"
    - "NoiseInjection"
    - "RandomRotation"
    - "MotionBlur"
  augmentation_probabilities_per_batch: 0.2  # 20% of the batch will have augmentations applied randomly
  augmentations:
    - type: "RandomHorizontalFlip"
      probability: 0.5
    - type: "RandomCrop"
      size: [600, 600]
    - type: "ColorJitter"
      brightness: 0.2
      contrast: 0.2
      saturation: 0.2
      hue: 0.1
    - type: "NoiseInjection"
      mean: 0
      std: 0.05
      p: 0.5
    - type: "RandomRotation"
      degrees: 10
      fill: "black"
    - type: "MotionBlur"
      kernel_size: 5
      p: 0.3

experiment:
  name: "gai-yolov12-experiment-{timestamp}"  # Use {timestamp} for automatic naming
  description: "Experimenting with GAI-YOLOv12 on BDD100K"
  output_dir: "experiments"
  log_interval: 10

# Evaluation settings
evaluation:
  eval_interval: 5  # Evaluate COCO metrics every N epochs
  coco_eval_batches: 100  # Limit number of batches for COCO evaluation
  enable_coco_eval: true

# Batch limitations for faster epochs
batch_limits:
  train_batches_per_epoch: 100  # Limit each epoch to N batches (null for no limit)
  val_batches_per_epoch: 50     # Limit validation batches (null for no limit)

# TensorBoard settings
tensorboard:
  enabled: true
  log_images: true
  image_log_interval: 100  # Log images every N batches
  images_per_batch: 2      # Number of images to log per batch
